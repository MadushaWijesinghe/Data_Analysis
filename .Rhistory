diabetes<-read.csv("C:/Users/A576/Desktop/KCGI/Semester2/Data Analysis2/Final_Project/diabetes.csv")
head(diabetes)
summary(diabetes)
str(diabetes)
tail(diabetes)
set.seed(123)
split_index <- sample(1:nrow(diabetes), 0.7 * nrow(diabetes))
train_data <- diabetes[split_index, ]
test_data <- diabetes[-split_index, ]
library(ggplot2)
library(reshape2)
ggplot(diabetes, aes(x = Glucose, fill = factor(Outcome))) +
geom_histogram(binwidth = 5, position = "dodge", color = "black", alpha = 0.7) +
labs(title = "Histogram of Glucose Levels by Diabetes Outcome",
x = "Glucose Level", y = "Frequency",
fill = "Outcome") +
theme_minimal()
correlation_matrix <- cor(diabetes[, -9])  # Calculate correlation matrix, excluding Outcome column
melted_correlation <- melt(correlation_matrix)  # Reshape correlation matrix for heatmap
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
labs(title = "Correlation Heatmap of Variables",
x = "Variable", y = "Variable",
fill = "Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "right")
# Load necessary libraries
library(randomForest)
# Assuming 'diabetes_data' is the dataframe containing the dataset
# Split the data into train and test sets (as done previously)
set.seed(123)
train_ratio <- 0.7
num_rows <- nrow(diabetes)
num_train <- round(train_ratio * num_rows)
train_indices <- sample(seq_len(num_rows), size = num_train, replace = FALSE)
train_data <- diabetes[train_indices, ]
test_data <- diabetes[-train_indices, ]
# Train the Random Forest model
rf_model <- randomForest(factor(Outcome) ~ ., data = train_data)
# Make predictions on the test set
predictions <- predict(rf_model, test_data)
# Evaluate model performance
conf_matrix <- table(test_data$Outcome, predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
# Print evaluation metrics
print(conf_matrix)
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
library(ggplot2)
library(cowplot)
install.packages("cowplot")
library(cowplot)
library(ggplot2)
library(cowplot)
library(randomForest)
diabetes <- read.csv("C:/Users/A576/Desktop/KCGI/Semester2/Data Analysis2/Final_Project/diabetes.csv")
head(diabetes)
diabetes$Outcome <-ifelse(test = diabetes$Outcome ==1, yes= "Positive", no = "Negative")
diabetes$Outcome <- as.factor(diabetes$Outcome)
diabetes.imputed <-rfImpute(Outcome~., data= diabetes, iter=6)
model <-randomForest(Outcome~., data= diabetes)
model
model2 <-randomForest(Outcome~., data= diabetes, ntree = 1000)
model2
oob.error.data <- data.frame(Trees = rep(1:nrow(model2$err.rate), times=3), Type = rep(c("OOB", "Negative", "Positive"), each = nrow(model2$err.rate)), Error = c(model2$err.rate[, "unhealthy"]))
oob.error.data <- data.frame(Trees = rep(1:nrow(model2$err.rate), times=3), Type = rep(c("OOB", "Negative", "Positive"), each = nrow(model2$err.rate)), Error = c(model2$err.rate[, "Negative"]))
oob.error.data <- data.frame(Trees = rep(1:nrow(model2$err.rate), times=3), Type = rep(c("OOB", "Negative", "Positive"), each = nrow(model2$err.rate)), Error = c(model2$err.rate[, "OBB"], model2$err.rate[, "Negative"], model2$err.rate[, "Positive"] ))
oob.error.data <- data.frame(Trees = rep(1:nrow(model2$err.rate), times=3), Type = rep(c("OOB", "Negative", "Positive"), each = nrow(model2$err.rate)), Error = c(model2$err.rate[,"OBB"], model2$err.rate[, "Negative"], model2$err.rate[, "Positive"] ))
oob.error.data <- data.frame(Trees = rep(1:nrow(model2$err.rate), times=2), Type = rep(c("OOB", "Negative", "Positive"), each = nrow(model2$err.rate)), Error = c(model2$err.rate[,"OBB"], model2$err.rate[, "Negative"], model2$err.rate[, "Positive"] ))
#find number of trees that produce lowest test MSE
which.min(model$mse)
#find RMSE of best model
sqrt(model$mse[which.min(model$mse)])
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes_data)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes_data' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data)
# Load necessary libraries
library(randomForest)
library(caret)
library(pROC)
library(ggplot2)
library(cowplot)
# Train the Random Forest model (assuming 'diabetes' is the dataframe containing the dataset)
set.seed(123)
rf_model <- randomForest(factor(Outcome) ~ ., data = diabetes)
# Model Summary
print(rf_model)
# Make predictions on the train and test sets
train_predictions <- predict(rf_model, diabetes)
test_predictions <- predict(rf_model, test_data)
# Model Evaluation Metrics
train_accuracy <- mean(train_predictions == diabetes$Outcome)
test_accuracy <- mean(test_predictions == test_data$Outcome)
# Convert test_predictions to factor with the same levels as test_data$Outcome
test_predictions <- factor(test_predictions, levels = levels(test_data$Outcome))
levels(test_data$Outcome)
levels(test_predictions)
# Confusion Matrix
conf_matrix<- confusionMatrix(data = test_predictions, reference = test_data$Outcome)
levels(test_data$Outcome)
levels(test_predictions)
# Evaluate model performance
conf_matrix <- table(test_data$Outcome, predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
# Print evaluation metrics
print(conf_matrix)
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
library(ggplot2)
library(cowplot)
library(randomForest)
diabetes <- read.csv("C:/Users/A576/Desktop/KCGI/Semester2/Data Analysis2/Final_Project/diabetes.csv")
head(diabetes)
diabetes$Outcome <-ifelse(test = diabetes$Outcome ==1, yes= "Positive", no = "Negative")
diabetes$Outcome <- as.factor(diabetes$Outcome)
model <-randomForest(Outcome~., data= diabetes)
model
model2 <-randomForest(Outcome~., data= diabetes, ntree = 1000)
model2
# Evaluate model performance
conf_matrix <- table(test_data$Outcome, predictions)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
# Print evaluation metrics
print(conf_matrix)
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
install.packages(c("cli", "data.table", "digest", "htmltools", "rlang"))
